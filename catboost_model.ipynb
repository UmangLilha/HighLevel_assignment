{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from catboost import CatBoostRegressor, Pool\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "import pickle as pkl\n",
    "\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_parquet('data_preprocessed.parquet')\n",
    "data = data[data.Impact != 0]\n",
    "X = data.drop('Impact', axis=1)\n",
    "y = data['Impact']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 73)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data.Impact == 0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 138723 entries, 0 to 138723\n",
      "Data columns (total 72 columns):\n",
      " #   Column               Non-Null Count   Dtype  \n",
      "---  ------               --------------   -----  \n",
      " 0   desc_length          138723 non-null  float64\n",
      " 1   title_length         138723 non-null  float64\n",
      " 2   embed_0              138723 non-null  float64\n",
      " 3   embed_1              138723 non-null  float64\n",
      " 4   embed_2              138723 non-null  float64\n",
      " 5   embed_3              138723 non-null  float64\n",
      " 6   embed_4              138723 non-null  float64\n",
      " 7   embed_5              138723 non-null  float64\n",
      " 8   embed_6              138723 non-null  float64\n",
      " 9   embed_7              138723 non-null  float64\n",
      " 10  embed_8              138723 non-null  float64\n",
      " 11  embed_9              138723 non-null  float64\n",
      " 12  embed_10             138723 non-null  float64\n",
      " 13  embed_11             138723 non-null  float64\n",
      " 14  embed_12             138723 non-null  float64\n",
      " 15  embed_13             138723 non-null  float64\n",
      " 16  embed_14             138723 non-null  float64\n",
      " 17  embed_15             138723 non-null  float64\n",
      " 18  embed_16             138723 non-null  float64\n",
      " 19  embed_17             138723 non-null  float64\n",
      " 20  embed_18             138723 non-null  float64\n",
      " 21  embed_19             138723 non-null  float64\n",
      " 22  embed_20             138723 non-null  float64\n",
      " 23  embed_21             138723 non-null  float64\n",
      " 24  embed_22             138723 non-null  float64\n",
      " 25  embed_23             138723 non-null  float64\n",
      " 26  embed_24             138723 non-null  float64\n",
      " 27  embed_25             138723 non-null  float64\n",
      " 28  embed_26             138723 non-null  float64\n",
      " 29  embed_27             138723 non-null  float64\n",
      " 30  embed_28             138723 non-null  float64\n",
      " 31  embed_29             138723 non-null  float64\n",
      " 32  embed_30             138723 non-null  float64\n",
      " 33  embed_31             138723 non-null  float64\n",
      " 34  embed_32             138723 non-null  float64\n",
      " 35  embed_33             138723 non-null  float64\n",
      " 36  embed_34             138723 non-null  float64\n",
      " 37  embed_35             138723 non-null  float64\n",
      " 38  embed_36             138723 non-null  float64\n",
      " 39  embed_37             138723 non-null  float64\n",
      " 40  embed_38             138723 non-null  float64\n",
      " 41  embed_39             138723 non-null  float64\n",
      " 42  embed_40             138723 non-null  float64\n",
      " 43  embed_41             138723 non-null  float64\n",
      " 44  embed_42             138723 non-null  float64\n",
      " 45  embed_43             138723 non-null  float64\n",
      " 46  embed_44             138723 non-null  float64\n",
      " 47  embed_45             138723 non-null  float64\n",
      " 48  embed_46             138723 non-null  float64\n",
      " 49  embed_47             138723 non-null  float64\n",
      " 50  embed_48             138723 non-null  float64\n",
      " 51  embed_49             138723 non-null  float64\n",
      " 52  embed_50             138723 non-null  float64\n",
      " 53  embed_51             138723 non-null  float64\n",
      " 54  embed_52             138723 non-null  float64\n",
      " 55  embed_53             138723 non-null  float64\n",
      " 56  embed_54             138723 non-null  float64\n",
      " 57  embed_55             138723 non-null  float64\n",
      " 58  embed_56             138723 non-null  float64\n",
      " 59  embed_57             138723 non-null  float64\n",
      " 60  embed_58             138723 non-null  float64\n",
      " 61  embed_59             138723 non-null  float64\n",
      " 62  embed_60             138723 non-null  float64\n",
      " 63  embed_61             138723 non-null  float64\n",
      " 64  embed_62             138723 non-null  float64\n",
      " 65  embed_63             138723 non-null  float64\n",
      " 66  publisher_encoded    138723 non-null  int64  \n",
      " 67  categories_encoded   138723 non-null  int64  \n",
      " 68  published_year       138723 non-null  float64\n",
      " 69  published_month      138723 non-null  float64\n",
      " 70  author_count         138723 non-null  int64  \n",
      " 71  main_author_encoded  138723 non-null  int64  \n",
      "dtypes: float64(68), int64(4)\n",
      "memory usage: 77.3 MB\n"
     ]
    }
   ],
   "source": [
    "X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_features = ['publisher_encoded','categories_encoded']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning\n",
    "- Using Optuna along with MAPE as the main objective function\n",
    "- using KFold cross validation with 3 splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    # Define the hyperparameters space to tune\n",
    "    param = {\n",
    "        'iterations': trial.suggest_int('iterations', 100, 2000),\n",
    "        'depth': trial.suggest_int('depth', 4, 10),\n",
    "        'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.05),\n",
    "        'min_child_samples': trial.suggest_int('min_child_samples', 5, 50),\n",
    "        'subsample': trial.suggest_uniform('subsample', 0.5, 1.0),\n",
    "        'colsample_bylevel': trial.suggest_uniform('colsample_bylevel', 0.5, 1.0),\n",
    "        'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 1, 10),\n",
    "\n",
    "    }\n",
    "    \n",
    "    # Initialize K-Fold cross-validation\n",
    "    kf = KFold(n_splits=3, shuffle=True, random_state=42)\n",
    "    \n",
    "    mape_scores = []\n",
    "    \n",
    "    # Perform K-Fold cross-validation\n",
    "    for train_index, valid_index in kf.split(X):\n",
    "        X_train, X_valid = X.iloc[train_index], X.iloc[valid_index]\n",
    "        y_train, y_valid = y.iloc[train_index], y.iloc[valid_index]\n",
    "        \n",
    "        train_pool = Pool(X_train, y_train, cat_features=cat_features)\n",
    "        valid_pool = Pool(X_valid, y_valid, cat_features=cat_features)\n",
    "        \n",
    "        model = CatBoostRegressor(**param)\n",
    "        model.fit(train_pool, eval_set=valid_pool, early_stopping_rounds=50, verbose=False)\n",
    "        \n",
    "        y_pred = model.predict(X_valid)\n",
    "        mape = mean_absolute_percentage_error(y_valid, y_pred)\n",
    "        mape_scores.append(mape)\n",
    "    \n",
    "    # Return the mean MAPE score\n",
    "    return sum(mape_scores) / len(mape_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=10)\n",
    "best_params = study.best_params\n",
    "best_value = study.best_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'iterations': 1925,\n",
       " 'depth': 10,\n",
       " 'learning_rate': 0.020709915830925664,\n",
       " 'min_child_samples': 38,\n",
       " 'subsample': 0.6685043598983783,\n",
       " 'colsample_bylevel': 0.9431467353861616,\n",
       " 'l2_leaf_reg': 1.099182957889465}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05552452805585498"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.best_value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using the best parameters found by optuna after rounding them off.\n",
    "best_params = {\n",
    "    'iterations': 2000,  \n",
    "    'depth': 10,        \n",
    "    'learning_rate': 0.02,  \n",
    "    'min_child_samples': 38,\n",
    "    'subsample': 0.7,\n",
    "    'colsample_bylevel': 0.9,\n",
    "    'l2_leaf_reg': 1.1,   \n",
    "    'random_seed': 42\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "mape_scores = []  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section of the code implements a 5-fold cross-validation training process for a CatBoost regression model. ]\n",
    "\n",
    "\n",
    "\n",
    "1. **Cross-Validation:**\n",
    "   - A 5-fold cross-validation is performed using KFold from scikit-learn.\n",
    "   - The data is split into training and validation sets for each fold.\n",
    "\n",
    "2. **Model Training:**\n",
    "   - For each fold:\n",
    "     - CatBoost Pool objects are created for training and validation data.\n",
    "     - A CatBoostRegressor is initialized with the best parameters found by Optuna.\n",
    "     - The model is trained using the training pool and evaluated on the validation pool.\n",
    "     - Early stopping is applied with a patience of 50 rounds.\n",
    "\n",
    "3. **Performance Evaluation:**\n",
    "   - Mean Absolute Percentage Error (MAPE) is calculated for each fold.\n",
    "   - The MAPE scores are printed for each fold and averaged at the end.\n",
    "\n",
    "\n",
    "\n",
    "4. **Final Results:**\n",
    "   - The average cross-validation MAPE is printed, giving an estimate of the model's performance.\n",
    "\n",
    "This process ensures a robust evaluation of the model's performance across different subsets of the data, helping to assess its generalization capability.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv-mape 0.058825163165431245\n",
      "cv-mape 0.05665670960545309\n",
      "cv-mape 0.057532631424358174\n",
      "cv-mape 0.057321023624930155\n",
      "cv-mape 0.06380823981148162\n",
      "avg_cv-mape 0.05882875352633086\n"
     ]
    }
   ],
   "source": [
    "X = X.drop(columns=['main_author_encoded'],axis=1) # dropping main_author_encoded as it did not lead to any improvement but increased training time\n",
    "for train_index, valid_index in kf.split(X):\n",
    "    X_train, X_valid = X.iloc[train_index], X.iloc[valid_index]\n",
    "    y_train, y_valid = y.iloc[train_index], y.iloc[valid_index]\n",
    "    \n",
    "    train_pool = Pool(X_train, y_train,cat_features=cat_features)\n",
    "    valid_pool = Pool(X_valid, y_valid,cat_features=cat_features)\n",
    "    \n",
    "    model = CatBoostRegressor( **best_params, loss_function='MAPE')\n",
    "    model.fit(train_pool, eval_set=valid_pool, early_stopping_rounds=50, verbose=False)\n",
    "    counter += 1\n",
    "    \n",
    "    y_pred = model.predict(X_valid)\n",
    "    mape = mean_absolute_percentage_error(y_valid, y_pred)\n",
    "    print(\"cv-mape\",mape)\n",
    "    mape_scores.append(mape)\n",
    "\n",
    "    #pkl.dump(model,open('model_catboost-{counter}-{mape}.pkl'.format(counter=counter,mape=mape),'wb'))\n",
    "    \n",
    "print(\"avg_cv-mape\",sum(mape_scores) / len(mape_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training the final model on the entire dataset using the best parameters found by optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train final model on all data using best parameters\n",
    "print(\"Training final model on all data...\")\n",
    "\n",
    "\n",
    "final_train_pool = Pool(X, y, cat_features=cat_features)\n",
    "final_model = CatBoostRegressor(**best_params, loss_function='MAPE')\n",
    "final_model.fit(final_train_pool, verbose=False)\n",
    "\n",
    "# Save the final model\n",
    "final_model_filename = 'final_model_catboost.pkl'\n",
    "pkl.dump(final_model, open(final_model_filename, 'wb'))\n",
    "print(f\"Final model saved as {final_model_filename}\")\n",
    "\n",
    "\n",
    "feature_importances = final_model.get_feature_importance(final_train_pool)\n",
    "feature_names = X.columns\n",
    "importance_df = pd.DataFrame({'feature': feature_names, 'importance': feature_importances})\n",
    "importance_df = importance_df.sort_values('importance', ascending=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>publisher_encoded</td>\n",
       "      <td>22.075848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>categories_encoded</td>\n",
       "      <td>17.229149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>embed_23</td>\n",
       "      <td>10.687276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>embed_8</td>\n",
       "      <td>7.063510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>embed_59</td>\n",
       "      <td>6.346241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>embed_22</td>\n",
       "      <td>3.061903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>embed_32</td>\n",
       "      <td>1.386646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>embed_62</td>\n",
       "      <td>1.309167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>published_year</td>\n",
       "      <td>1.305364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>embed_18</td>\n",
       "      <td>1.267009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>embed_16</td>\n",
       "      <td>1.239825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>embed_27</td>\n",
       "      <td>1.052665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>desc_length</td>\n",
       "      <td>0.897210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>embed_15</td>\n",
       "      <td>0.841570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>embed_47</td>\n",
       "      <td>0.809696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>embed_19</td>\n",
       "      <td>0.774759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>embed_40</td>\n",
       "      <td>0.738171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>embed_53</td>\n",
       "      <td>0.706738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>embed_3</td>\n",
       "      <td>0.690956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>embed_28</td>\n",
       "      <td>0.671020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>embed_14</td>\n",
       "      <td>0.641268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>embed_41</td>\n",
       "      <td>0.640176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>embed_30</td>\n",
       "      <td>0.632517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>embed_31</td>\n",
       "      <td>0.613872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>embed_10</td>\n",
       "      <td>0.608818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>embed_1</td>\n",
       "      <td>0.597471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>embed_60</td>\n",
       "      <td>0.586623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>embed_58</td>\n",
       "      <td>0.578897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>embed_4</td>\n",
       "      <td>0.573665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>embed_57</td>\n",
       "      <td>0.571160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>embed_0</td>\n",
       "      <td>0.512669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>embed_11</td>\n",
       "      <td>0.500347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>embed_49</td>\n",
       "      <td>0.493262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>embed_45</td>\n",
       "      <td>0.488177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>embed_7</td>\n",
       "      <td>0.477527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>embed_50</td>\n",
       "      <td>0.477224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>published_month</td>\n",
       "      <td>0.468056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>embed_55</td>\n",
       "      <td>0.448990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>embed_46</td>\n",
       "      <td>0.430968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>embed_52</td>\n",
       "      <td>0.420791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>embed_38</td>\n",
       "      <td>0.418015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>embed_35</td>\n",
       "      <td>0.416423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>embed_6</td>\n",
       "      <td>0.411082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>embed_25</td>\n",
       "      <td>0.401382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>embed_42</td>\n",
       "      <td>0.389489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>embed_9</td>\n",
       "      <td>0.379342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>embed_12</td>\n",
       "      <td>0.376331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>embed_61</td>\n",
       "      <td>0.373324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>embed_36</td>\n",
       "      <td>0.331577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>embed_29</td>\n",
       "      <td>0.325702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>embed_39</td>\n",
       "      <td>0.318364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>embed_44</td>\n",
       "      <td>0.312957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>embed_51</td>\n",
       "      <td>0.312784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>embed_13</td>\n",
       "      <td>0.311462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>embed_20</td>\n",
       "      <td>0.303921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>embed_33</td>\n",
       "      <td>0.303506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>embed_5</td>\n",
       "      <td>0.303426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>title_length</td>\n",
       "      <td>0.297968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>embed_63</td>\n",
       "      <td>0.281668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>embed_2</td>\n",
       "      <td>0.270714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>embed_54</td>\n",
       "      <td>0.264655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>embed_37</td>\n",
       "      <td>0.251672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>embed_17</td>\n",
       "      <td>0.239478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>embed_26</td>\n",
       "      <td>0.239413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>embed_34</td>\n",
       "      <td>0.231250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>embed_56</td>\n",
       "      <td>0.214953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>embed_21</td>\n",
       "      <td>0.204242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>embed_48</td>\n",
       "      <td>0.199769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>embed_24</td>\n",
       "      <td>0.184701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>embed_43</td>\n",
       "      <td>0.144341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>author_count</td>\n",
       "      <td>0.068889</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               feature  importance\n",
       "66   publisher_encoded   22.075848\n",
       "67  categories_encoded   17.229149\n",
       "25            embed_23   10.687276\n",
       "10             embed_8    7.063510\n",
       "61            embed_59    6.346241\n",
       "24            embed_22    3.061903\n",
       "34            embed_32    1.386646\n",
       "64            embed_62    1.309167\n",
       "68      published_year    1.305364\n",
       "20            embed_18    1.267009\n",
       "18            embed_16    1.239825\n",
       "29            embed_27    1.052665\n",
       "0          desc_length    0.897210\n",
       "17            embed_15    0.841570\n",
       "49            embed_47    0.809696\n",
       "21            embed_19    0.774759\n",
       "42            embed_40    0.738171\n",
       "55            embed_53    0.706738\n",
       "5              embed_3    0.690956\n",
       "30            embed_28    0.671020\n",
       "16            embed_14    0.641268\n",
       "43            embed_41    0.640176\n",
       "32            embed_30    0.632517\n",
       "33            embed_31    0.613872\n",
       "12            embed_10    0.608818\n",
       "3              embed_1    0.597471\n",
       "62            embed_60    0.586623\n",
       "60            embed_58    0.578897\n",
       "6              embed_4    0.573665\n",
       "59            embed_57    0.571160\n",
       "2              embed_0    0.512669\n",
       "13            embed_11    0.500347\n",
       "51            embed_49    0.493262\n",
       "47            embed_45    0.488177\n",
       "9              embed_7    0.477527\n",
       "52            embed_50    0.477224\n",
       "69     published_month    0.468056\n",
       "57            embed_55    0.448990\n",
       "48            embed_46    0.430968\n",
       "54            embed_52    0.420791\n",
       "40            embed_38    0.418015\n",
       "37            embed_35    0.416423\n",
       "8              embed_6    0.411082\n",
       "27            embed_25    0.401382\n",
       "44            embed_42    0.389489\n",
       "11             embed_9    0.379342\n",
       "14            embed_12    0.376331\n",
       "63            embed_61    0.373324\n",
       "38            embed_36    0.331577\n",
       "31            embed_29    0.325702\n",
       "41            embed_39    0.318364\n",
       "46            embed_44    0.312957\n",
       "53            embed_51    0.312784\n",
       "15            embed_13    0.311462\n",
       "22            embed_20    0.303921\n",
       "35            embed_33    0.303506\n",
       "7              embed_5    0.303426\n",
       "1         title_length    0.297968\n",
       "65            embed_63    0.281668\n",
       "4              embed_2    0.270714\n",
       "56            embed_54    0.264655\n",
       "39            embed_37    0.251672\n",
       "19            embed_17    0.239478\n",
       "28            embed_26    0.239413\n",
       "36            embed_34    0.231250\n",
       "58            embed_56    0.214953\n",
       "23            embed_21    0.204242\n",
       "50            embed_48    0.199769\n",
       "26            embed_24    0.184701\n",
       "45            embed_43    0.144341\n",
       "70        author_count    0.068889"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "importance_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "belvilla",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
